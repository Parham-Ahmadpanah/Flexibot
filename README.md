# Flexibot
In this project, a continuum robot is developed with 16 degrees of freedom (16 actuators) integrated with computer vision capabilities. The design of this robot draws inspiration from nature, particularly from snakes, and is designed for the purpose of collecting cigarette butts from the ground.

## Bringing the Idea to Life
Body:
Initially, I experimented with various body designs, eventually settling on an elastic body with a plastic-polyester texture. This material offers the necessary elasticity for flexibility and sufficient strength to withstand bending and torsion tension. Strong strings are employed as tendons to efficiently transfer the torque generated by the actuators to the main body structure.

Actuators:
To drive the robotâ€™s movements, I utilized 16 MG90S servomotors controlled through an Arduino Uno board in collaboration with a PCA9685 module. Each MG90S servomotor features a 5V power pin, a ground pin, and a PWM pin. Given the limited number of PWM pins on the Arduino Uno board, I integrated the PCA9685 module, which provides 16 additional PWM pins for seamless control of all 16 servomotors.

<div style="display: flex;">
    <img src="Data\Img1.png" alt="Image 1" style="width: 45%;">
    <img src="Data\Img2.jpg" alt="Image 2" style="width: 30%;">
</div>

For grabing the cigar butts I used an air pump (12v, Debi:15Lit/min). I control it using a mosfet, a power source, and an arduino digital pin.
<div style="display: flex;">
    <img src="Data\Img3.jpg" alt="Image 3" style="width: 30%;">
</div>

Sensor:
An important component of this project is the camera sensor employed for tracking the end effector and cigarette butts. By training a model on YOLOv8 with classes for cigarettes and end effectors, the camera effectively detects bounding boxes around these objects. By finding the coordinates of these bounding boxes, the robot can accurately estimate the positions of the detected objects, aided by the fixed positioning of the camera.

## Phase 1: Detection
First I gathered a dataset for cigar butts and the end effector of Flexibot. After augmentation, I had over 4600 images split for train, validation, and test. After several times, I trained the model with YOLOv8, and I reached the desired one that detected every cigar butt and the end effector simultaneously.
![Flexibot_detection](Data/Detection1.gif)
<video width="640" height="360" controls>
  <source src="Data/Detection1.gif" type="video/gif">
</video>

## Phase 2: Path Planning
First, I programmed the motors and connected them to my Python environment using the serial port. After controlling each motor angle, I could save the data of the motor angles with the coordination of the end effector in the image. With this data, I am capable of using it for controlling the end effector based on its coordination.

To be continued after publishing the paper...
